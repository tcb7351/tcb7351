{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcb7351/tcb7351/blob/20231206_2/%5BNLP_2023%5D_Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus Preparation"
      ],
      "metadata": {
        "id": "OIpik4lkdB3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "nltk.download('brown')\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "corpus = []\n",
        "for sent in brown.sents():\n",
        "    corpus.append([w.lower() for w in sent])\n",
        "print(corpus[0])"
      ],
      "metadata": {
        "id": "EraTM0S0B0rM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc82b770-1994-4156-9e5e-154930efbbfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', \"atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Counter()\n",
        "for s in corpus:\n",
        "    for w in s:\n",
        "        vocab[w] += 1\n",
        "\n",
        "word_to_id = {\"<unk>\": 0, \"<s>\": 1}\n",
        "for w, c in vocab.most_common():\n",
        "    if c < 20:\n",
        "        break\n",
        "    word_to_id[w] = len(word_to_id)\n",
        "\n",
        "print(len(word_to_id))"
      ],
      "metadata": {
        "id": "vMtzKGa5CDs4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f0f2ba1-cdcb-4bef-96f1-a34ce5d3178f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using PyTorch\n",
        "\n",
        "The code is taken from https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html"
      ],
      "metadata": {
        "id": "ont9_h7SdGgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vwvY-uxc_5u",
        "outputId": "13154b93-a8f0-4796-c42f-549b0cf7904d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3e0f19a950>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 20\n",
        "VOCAB_SIZE = len(word_to_id)\n",
        "\n",
        "embeds = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
        "lookup_tensor = torch.tensor([word_to_id[\"country\"]], dtype=torch.long)\n",
        "print(embeds(lookup_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBFPrnzZb2gs",
        "outputId": "f4b6fce8-1aa0-4a91-f623-3b5246f9c9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.7584,  1.3751, -0.0024, -0.6730, -0.1112, -1.9805, -0.9982,  0.6384,\n",
            "         -2.0778,  1.3597, -0.8795,  0.4062,  0.6346, -0.1749, -1.8811,  1.0915,\n",
            "          0.2510, -0.1448,  0.4096, -0.9203]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW Language Model"
      ],
      "metadata": {
        "id": "O5thBMcjfO49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(CBOW, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(context_size * 2 * embedding_dim, 50)\n",
        "        self.linear2 = nn.Linear(50, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view((1, -1))\n",
        "        out = F.relu(self.linear1(embeds))\n",
        "        out = self.linear2(out)\n",
        "        log_probs = F.log_softmax(out, dim=1)\n",
        "        return log_probs"
      ],
      "metadata": {
        "id": "oBcs3ziCc9Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "CONTEXT_SIZE = 3\n",
        "EMBEDDING_DIM = 20\n",
        "VOCAB_SIZE = len(word_to_id)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train():\n",
        "    contexts = []\n",
        "    targets = []\n",
        "    for s in corpus:\n",
        "        for i in range(len(s)):\n",
        "            target = word_to_id[s[i]] if s[i] in word_to_id else word_to_id[\"<unk>\"]\n",
        "            context = []\n",
        "            for j in range(i-CONTEXT_SIZE, i+CONTEXT_SIZE+1):\n",
        "                if j == i:\n",
        "                    continue\n",
        "                wc = s[j] if 0 <= j < len(s) else \"<s>\"\n",
        "                wc = word_to_id[wc] if wc in word_to_id else word_to_id[\"<unk>\"]\n",
        "                context.append(wc)\n",
        "            contexts.append(context)\n",
        "            targets.append([target])\n",
        "    print(len(contexts), len(targets))\n",
        "    print(contexts[0], targets[0])\n",
        "\n",
        "    contexts = torch.tensor(contexts, dtype=torch.long).to(device)\n",
        "    targets = torch.tensor(targets, dtype=torch.long).to(device)\n",
        "\n",
        "    losses = []\n",
        "    loss_function = nn.NLLLoss() # Negative likelihood loss\n",
        "    model = CBOW(VOCAB_SIZE, EMBEDDING_DIM, CONTEXT_SIZE).to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in tqdm.trange(NUM_EPOCHS):\n",
        "        total_loss = 0\n",
        "        for context, target in zip(contexts, targets):\n",
        "            model.zero_grad()\n",
        "            log_probs = model(context)\n",
        "            loss = loss_function(log_probs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(total_loss)\n",
        "    return model\n",
        "\n",
        "model = train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKW7c6qce4Z-",
        "outputId": "c638648e-1c3e-4b50-d605-a18a7861755f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1161192 1161192\n",
            "[1, 1, 1, 0, 652, 2297] [2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 1/3 [15:50<31:40, 950.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5829712.189111054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [31:38<15:49, 949.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5404481.153046466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [47:25<00:00, 948.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5220841.668642633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.embeddings.weight[word_to_id[\"nice\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjwaE8XkiuzS",
        "outputId": "b2b7a28e-d95f-4fcb-eb2f-6bf770fb9d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4.4142e-04,  3.4940e-01,  3.6838e-01,  1.6032e+00, -6.4265e-01,\n",
            "         1.8571e+00,  6.1649e-01,  1.8254e+00, -5.8889e-01, -1.7467e+00,\n",
            "         8.2054e-01, -1.0854e+00,  3.4049e-01, -8.1458e-01, -1.1703e-01,\n",
            "        -2.8776e-01,  1.5662e+00,  1.2633e+00, -4.8334e-01, -6.0228e-02],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def similarity(w1, w2):\n",
        "    return cosine_similarity([model.embeddings.weight[word_to_id[w1]].cpu().detach().numpy()],\n",
        "                             [model.embeddings.weight[word_to_id[w2]].cpu().detach().numpy()])"
      ],
      "metadata": {
        "id": "4sYMo0ogpF6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(similarity(\"good\", \"bad\"))\n",
        "print(similarity(\"good\", \"excellent\"))\n",
        "print(similarity(\"good\", \"tree\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uTidXCsJzAi",
        "outputId": "38ef26ed-cf3f-44b8-8939-569cb6e9a2d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.21657313]]\n",
            "[[0.32453555]]\n",
            "[[-0.05597425]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVb49qv8K2vx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}